{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Compiling Data with MongoDB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Databases\n",
    "\n",
    "Start up mongoDB. There are two json files (`tweets2.json` and `tweets4.json`) that need to be imported into the database. This can be done using the terminal commands below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mongoimport --db tweets --collection tweets2 --file tweets2.json  \n",
    "\n",
    "mongoimport --db tweets --collection tweets4 --file tweets4.json\n",
    "```\n",
    "\n",
    "The `tweets` database has two collections: `tweets2` and `tweets4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Through Tweets Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all tweets in the database are desired for this project. Specifically, we are not concerned with the following:\n",
    "\n",
    "1. **Retweets**\n",
    "2. **Tweets without location info**\n",
    "    - We want to analyze geographical trends, so tweets without a location attached to them are not desirable.\n",
    "    \n",
    "Queries will need to filter out these tweets; all retweets will be omitted, and then any location-related fields (e.g. user.location, geo.coordinates, place.full_name, place.country, and place.country_code) will be called and evaluated.\n",
    "\n",
    "___\n",
    "- Fields that will be called in query\n",
    "    - created_at\n",
    "    - id\n",
    "    - full_text\n",
    "    - entities.hashtags\n",
    "    - user.name\n",
    "    - user.screen_name\n",
    "    - user.location\n",
    "    - user.followers_count\n",
    "    - user.friends_count\n",
    "    - user.created_at\n",
    "    - user.verified\n",
    "    - user.statuses_count\n",
    "    - geo.coordinates\n",
    "    - place.full_name\n",
    "    - place.country\n",
    "    - place.country_code\n",
    "    - retweet_count\n",
    "    - favorite_count\n",
    "    - lang\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewgraves/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tweets2', 'tweets4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that tweets2 and tweets4 collections have been successfully\n",
    "# uploaded to the database.\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for `tweets2` collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets2_cursor = db.tweets2.find({\n",
    "                                'retweeted_status': {'$exists': False},\n",
    "#                                 'geo': {'$ne': None},\n",
    "#                                 'user.location': {'$ne': None},\n",
    "#                                 'place.country_code': 'US',\n",
    "                                'lang': 'en'},\n",
    "                               {'created_at': 1, \n",
    "                                'id': 1,\n",
    "                                'full_text': 1,\n",
    "                                'entities.hashtags': 1,\n",
    "                                'user.name': 1,\n",
    "                                'user.screen_name': 1,\n",
    "                                'user.location': 1,\n",
    "                                'user.followers_count': 1,\n",
    "                                'user.friends_count': 1,\n",
    "                                'user.created_at': 1,\n",
    "                                'user.verified': 1,\n",
    "                                'user.statuses_count': 1,\n",
    "                                'geo.coordinates': 1,\n",
    "                                'place.full_name': 1,\n",
    "                                'place.country': 1,\n",
    "                                'place.country_code': 1,\n",
    "                                'retweet_count': 1,\n",
    "                                'favorite_count': 1,\n",
    "                                'lang': 1}\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for `tweets4` collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets4_cursor = db.tweets4.find({\n",
    "                                'retweeted_status': {'$exists': False},\n",
    "#                                 'geo': {'$ne': None},\n",
    "#                                 'user.location': {'$ne': None},\n",
    "#                                 'place.country_code': 'US',\n",
    "                                'lang': 'en'},\n",
    "                               {'created_at': 1, \n",
    "                                'id': 1,\n",
    "                                'full_text': 1,\n",
    "                                'entities.hashtags': 1,\n",
    "                                'user.name': 1,\n",
    "                                'user.screen_name': 1,\n",
    "                                'user.location': 1,\n",
    "                                'user.followers_count': 1,\n",
    "                                'user.friends_count': 1,\n",
    "                                'user.created_at': 1,\n",
    "                                'user.verified': 1,\n",
    "                                'user.statuses_count': 1,\n",
    "                                'geo.coordinates': 1,\n",
    "                                'place.full_name': 1,\n",
    "                                'place.country': 1,\n",
    "                                'place.country_code': 1,\n",
    "                                'retweet_count': 1,\n",
    "                                'favorite_count': 1,\n",
    "                                'lang': 1}\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `tweets_df` from cursors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_generator(cursor_1, cursor_2):\n",
    "   \n",
    "    '''\n",
    "    Takes in two cursors, converts them into dataframes, then\n",
    "    appends the second dataframe to the first dataframe.\n",
    "    '''\n",
    "    \n",
    "    df_1 = pd.DataFrame(list(cursor_1))\n",
    "    df_2 = pd.DataFrame(list(cursor_2))\n",
    "    \n",
    "    df_combined = df_1.append(df_2)\n",
    "    \n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = df_generator(tweets2_cursor, tweets4_cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4225416 entries, 0 to 4225415\n",
      "Data columns (total 11 columns):\n",
      "_id               object\n",
      "created_at        object\n",
      "entities          object\n",
      "favorite_count    int64\n",
      "full_text         object\n",
      "geo               object\n",
      "id                int64\n",
      "lang              object\n",
      "place             object\n",
      "retweet_count     int64\n",
      "user              object\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 354.6+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up `tweets_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the dataframe was converted from the mongoDB cursors, some of the columns (specifically \"entities\", \"user\", and \"place\") contain embedded information. Data will need to be extracted from these columns so that they're easily accessible when using `tweets_df` later on.  \n",
    "\n",
    "A list will be created for each field of interest from these columns. They will then be organized into a dictionary, converted into a dataframe, and added to `tweets_df`.\n",
    "\n",
    "Additional cleaning will be performed after that, such as:\n",
    "- Deleting redundant and/or unnecessary columns\n",
    "- Converting date columns to datetime and adding new columns\n",
    "- Removing emojis from tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Hashtags from \"Entities\" Column\n",
    "- Ultimately, we want to create a list of hashtags for each tweet (i.e. `hashtags_list` below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_prelim_list = []\n",
    "\n",
    "for index, rows in tweets_df['entities'].iteritems():\n",
    "    for key, value in rows.items():\n",
    "        if key == 'hashtags':\n",
    "            hashtags_prelim_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_spec_list = []\n",
    "hashtags_list = []\n",
    "\n",
    "for lists in hashtags_prelim_list:\n",
    "    for i in lists:\n",
    "        if type(i) == dict:\n",
    "            for key, value in i.items():\n",
    "                if key == 'text':\n",
    "                    hashtags_spec_list.append(value)\n",
    "    hashtags_list.append(hashtags_spec_list)\n",
    "    hashtags_spec_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4225416"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hashtags_list) # Verify length of list = length of tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract User Info from \"User\" Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the information from the following fields in the \"user\" column:\n",
    "- user.name\n",
    "- user.screen_name\n",
    "- user.location\n",
    "- user.followers_count\n",
    "- user.friends_count\n",
    "- user.created_at\n",
    "- user.verified\n",
    "- user.statuses_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "screen_name_list = []\n",
    "location_list = []\n",
    "followers_count_list = []\n",
    "friends_count_list = []\n",
    "user_created_at_list = []\n",
    "verified_list = []\n",
    "statuses_count_list = []\n",
    "\n",
    "\n",
    "for index, rows in tweets_df['user'].iteritems():\n",
    "    for key, value in rows.items():\n",
    "        if key == 'name':\n",
    "            name_list.append(value)\n",
    "        elif key == 'screen_name':\n",
    "            screen_name_list.append(value)\n",
    "        elif key == 'location':\n",
    "            location_list.append(value)\n",
    "        elif key == 'followers_count':\n",
    "            followers_count_list.append(value)\n",
    "        elif key == 'friends_count':\n",
    "            friends_count_list.append(value)\n",
    "        elif key == 'created_at':\n",
    "            user_created_at_list.append(value)\n",
    "        elif key == 'verified':\n",
    "            verified_list.append(value)\n",
    "        elif key == 'statuses_count':\n",
    "            statuses_count_list.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Place Info from \"Place\" Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the information from the following fields in the \"place\" column:\n",
    "- place.full_name\n",
    "- place.country\n",
    "- place.country_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name_list = []\n",
    "place_country_list = []\n",
    "place_country_code_list = []\n",
    "\n",
    "\n",
    "for index, rows in tweets_df['place'].iteritems():\n",
    "    if type(rows) == dict:\n",
    "        for key, value in rows.items():\n",
    "            if key == 'full_name':\n",
    "                place_name_list.append(value)\n",
    "            elif key == 'country':\n",
    "                place_country_list.append(value)\n",
    "            elif key == 'country_code':\n",
    "                place_country_code_list.append(value)\n",
    "    else:\n",
    "        place_name_list.append(np.nan)\n",
    "        place_country_list.append(np.nan)\n",
    "        place_country_code_list.append(np.nan)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create supplemental dataframe, add to `tweets_df`, and perform more cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_supp_dict = {'Hashtags_List': hashtags_list,\n",
    "                   'User_Name': name_list,\n",
    "                   'User_Screen_Name': screen_name_list,\n",
    "                   'User_Status_Count': statuses_count_list,\n",
    "                   'User_Followers_Count': followers_count_list,\n",
    "                   'User_Friends_Count': friends_count_list,\n",
    "                   'User_Verified_Status': verified_list,\n",
    "                   'User_Account_Start_Date': user_created_at_list,\n",
    "                   'User_Location': location_list,\n",
    "                   'Tweet_Location': place_name_list,\n",
    "                   'Tweet_Location_Country': place_country_list,\n",
    "                   'Tweet_Location_Country_Code': place_country_code_list}\n",
    "\n",
    "tweet_supp_df = pd.DataFrame(tweet_supp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4225416 entries, 0 to 4225415\n",
      "Data columns (total 12 columns):\n",
      "Hashtags_List                  object\n",
      "User_Name                      object\n",
      "User_Screen_Name               object\n",
      "User_Status_Count              int64\n",
      "User_Followers_Count           int64\n",
      "User_Friends_Count             int64\n",
      "User_Verified_Status           bool\n",
      "User_Account_Start_Date        object\n",
      "User_Location                  object\n",
      "Tweet_Location                 object\n",
      "Tweet_Location_Country         object\n",
      "Tweet_Location_Country_Code    object\n",
      "dtypes: bool(1), int64(3), object(8)\n",
      "memory usage: 358.6+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet_supp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_full_df = pd.merge(tweets_df, tweet_supp_df, on=tweets_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4225416 entries, 0 to 4225415\n",
      "Data columns (total 24 columns):\n",
      "key_0                          int64\n",
      "_id                            object\n",
      "created_at                     object\n",
      "entities                       object\n",
      "favorite_count                 int64\n",
      "full_text                      object\n",
      "geo                            object\n",
      "id                             int64\n",
      "lang                           object\n",
      "place                          object\n",
      "retweet_count                  int64\n",
      "user                           object\n",
      "Hashtags_List                  object\n",
      "User_Name                      object\n",
      "User_Screen_Name               object\n",
      "User_Status_Count              int64\n",
      "User_Followers_Count           int64\n",
      "User_Friends_Count             int64\n",
      "User_Verified_Status           bool\n",
      "User_Account_Start_Date        object\n",
      "User_Location                  object\n",
      "Tweet_Location                 object\n",
      "Tweet_Location_Country         object\n",
      "Tweet_Location_Country_Code    object\n",
      "dtypes: bool(1), int64(7), object(16)\n",
      "memory usage: 777.7+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>User_Screen_Name</th>\n",
       "      <th>User_Status_Count</th>\n",
       "      <th>User_Followers_Count</th>\n",
       "      <th>User_Friends_Count</th>\n",
       "      <th>User_Verified_Status</th>\n",
       "      <th>User_Account_Start_Date</th>\n",
       "      <th>User_Location</th>\n",
       "      <th>Tweet_Location</th>\n",
       "      <th>Tweet_Location_Country</th>\n",
       "      <th>Tweet_Location_Country_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5e27ac4ae88fe0ef3b045b88</td>\n",
       "      <td>Tue Nov 27 02:45:12 +0000 2018</td>\n",
       "      <td>{'hashtags': []}</td>\n",
       "      <td>0</td>\n",
       "      <td>@DRUDGE_REPORT Climate change is not about cli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067247943491702784</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>All4Feedom</td>\n",
       "      <td>1176</td>\n",
       "      <td>51</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>Thu May 24 05:06:44 +0000 2018</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5e27ac4ae88fe0ef3b045b89</td>\n",
       "      <td>Tue Nov 27 02:45:11 +0000 2018</td>\n",
       "      <td>{'hashtags': []}</td>\n",
       "      <td>3</td>\n",
       "      <td>@juliabanksmp The statement clearly put the vi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067247939439943680</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Zwickyhumason1</td>\n",
       "      <td>577</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>Fri Oct 14 19:01:14 +0000 2016</td>\n",
       "      <td>Zwettl-Lower Austria, Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5e27ac4ae88fe0ef3b045b8a</td>\n",
       "      <td>Tue Nov 27 02:45:12 +0000 2018</td>\n",
       "      <td>{'hashtags': []}</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC News - Trump on climate change report: 'I ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067247941960626176</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rbmumsie</td>\n",
       "      <td>118235</td>\n",
       "      <td>952</td>\n",
       "      <td>609</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun Apr 21 23:44:26 +0000 2013</td>\n",
       "      <td>Colorado,  USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5e27ac4ae88fe0ef3b045b8c</td>\n",
       "      <td>Tue Nov 27 02:45:12 +0000 2018</td>\n",
       "      <td>{'hashtags': [{'text': 'climatechange', 'indic...</td>\n",
       "      <td>0</td>\n",
       "      <td>The info on #climatechange the tRump regime di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067247940094222342</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>booksanescape</td>\n",
       "      <td>83238</td>\n",
       "      <td>12482</td>\n",
       "      <td>13600</td>\n",
       "      <td>False</td>\n",
       "      <td>Thu Jun 13 03:15:34 +0000 2013</td>\n",
       "      <td>Cali Girl, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5e27ac4ae88fe0ef3b045b96</td>\n",
       "      <td>Tue Nov 27 02:45:16 +0000 2018</td>\n",
       "      <td>{'hashtags': [{'text': 'climatechange', 'indic...</td>\n",
       "      <td>0</td>\n",
       "      <td>.Gov. Defensor of Iloilo: “I have no idea abou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067247957508911105</td>\n",
       "      <td>en</td>\n",
       "      <td>{'full_name': 'Iloilo City, Western Visayas', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>icleiseas</td>\n",
       "      <td>2718</td>\n",
       "      <td>996</td>\n",
       "      <td>386</td>\n",
       "      <td>False</td>\n",
       "      <td>Fri Dec 13 09:50:27 +0000 2013</td>\n",
       "      <td>Manila, Philippines</td>\n",
       "      <td>Iloilo City, Western Visayas</td>\n",
       "      <td>Republic of the Philippines</td>\n",
       "      <td>PH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5e27ac4ae88fe0ef3b045b9a</td>\n",
       "      <td>Tue Nov 27 02:45:17 +0000 2018</td>\n",
       "      <td>{'hashtags': []}</td>\n",
       "      <td>0</td>\n",
       "      <td>if you start your sentence with I'm  not a sci...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067247961434861568</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>i_sharyn</td>\n",
       "      <td>8062</td>\n",
       "      <td>27</td>\n",
       "      <td>194</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Jul 03 00:55:41 +0000 2018</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5e27ac4ae88fe0ef3b045ba3</td>\n",
       "      <td>Tue Nov 27 02:45:18 +0000 2018</td>\n",
       "      <td>{'hashtags': []}</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Buffoonery, rather pure ignorance. https:/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067247967361556480</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>RobertLongView</td>\n",
       "      <td>4464</td>\n",
       "      <td>27</td>\n",
       "      <td>108</td>\n",
       "      <td>False</td>\n",
       "      <td>Thu Sep 06 02:27:46 +0000 2012</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5e27ac4ae88fe0ef3b045ba4</td>\n",
       "      <td>Tue Nov 27 02:45:18 +0000 2018</td>\n",
       "      <td>{'hashtags': []}</td>\n",
       "      <td>7</td>\n",
       "      <td>Sen. Mike Lee gives a perfectly ridiculous rea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067247966363238400</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>thinkprogress</td>\n",
       "      <td>152355</td>\n",
       "      <td>826870</td>\n",
       "      <td>892</td>\n",
       "      <td>True</td>\n",
       "      <td>Thu Jul 09 20:42:08 +0000 2009</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5e27ac4ae88fe0ef3b045ba5</td>\n",
       "      <td>Tue Nov 27 02:45:21 +0000 2018</td>\n",
       "      <td>{'hashtags': []}</td>\n",
       "      <td>0</td>\n",
       "      <td>@CNN Well, maybe the Global warming might even...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067247979118120960</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PaulusMcNaulus</td>\n",
       "      <td>5059</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun Apr 24 15:20:14 +0000 2016</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5e27ac4ae88fe0ef3b045bbf</td>\n",
       "      <td>Tue Nov 27 02:45:26 +0000 2018</td>\n",
       "      <td>{'hashtags': []}</td>\n",
       "      <td>1</td>\n",
       "      <td>Add...\\nA bunch of government scientists lande...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067248002178404353</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>AlamoOnTheRise</td>\n",
       "      <td>132668</td>\n",
       "      <td>26195</td>\n",
       "      <td>26169</td>\n",
       "      <td>False</td>\n",
       "      <td>Thu Apr 01 02:56:57 +0000 2010</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   key_0                       _id                      created_at  \\\n",
       "0      0  5e27ac4ae88fe0ef3b045b88  Tue Nov 27 02:45:12 +0000 2018   \n",
       "1      1  5e27ac4ae88fe0ef3b045b89  Tue Nov 27 02:45:11 +0000 2018   \n",
       "2      2  5e27ac4ae88fe0ef3b045b8a  Tue Nov 27 02:45:12 +0000 2018   \n",
       "3      3  5e27ac4ae88fe0ef3b045b8c  Tue Nov 27 02:45:12 +0000 2018   \n",
       "4      4  5e27ac4ae88fe0ef3b045b96  Tue Nov 27 02:45:16 +0000 2018   \n",
       "5      5  5e27ac4ae88fe0ef3b045b9a  Tue Nov 27 02:45:17 +0000 2018   \n",
       "6      6  5e27ac4ae88fe0ef3b045ba3  Tue Nov 27 02:45:18 +0000 2018   \n",
       "7      7  5e27ac4ae88fe0ef3b045ba4  Tue Nov 27 02:45:18 +0000 2018   \n",
       "8      8  5e27ac4ae88fe0ef3b045ba5  Tue Nov 27 02:45:21 +0000 2018   \n",
       "9      9  5e27ac4ae88fe0ef3b045bbf  Tue Nov 27 02:45:26 +0000 2018   \n",
       "\n",
       "                                            entities  favorite_count  \\\n",
       "0                                   {'hashtags': []}               0   \n",
       "1                                   {'hashtags': []}               3   \n",
       "2                                   {'hashtags': []}               0   \n",
       "3  {'hashtags': [{'text': 'climatechange', 'indic...               0   \n",
       "4  {'hashtags': [{'text': 'climatechange', 'indic...               0   \n",
       "5                                   {'hashtags': []}               0   \n",
       "6                                   {'hashtags': []}               0   \n",
       "7                                   {'hashtags': []}               7   \n",
       "8                                   {'hashtags': []}               0   \n",
       "9                                   {'hashtags': []}               1   \n",
       "\n",
       "                                           full_text  geo  \\\n",
       "0  @DRUDGE_REPORT Climate change is not about cli...  NaN   \n",
       "1  @juliabanksmp The statement clearly put the vi...  NaN   \n",
       "2  BBC News - Trump on climate change report: 'I ...  NaN   \n",
       "3  The info on #climatechange the tRump regime di...  NaN   \n",
       "4  .Gov. Defensor of Iloilo: “I have no idea abou...  NaN   \n",
       "5  if you start your sentence with I'm  not a sci...  NaN   \n",
       "6  Not Buffoonery, rather pure ignorance. https:/...  NaN   \n",
       "7  Sen. Mike Lee gives a perfectly ridiculous rea...  NaN   \n",
       "8  @CNN Well, maybe the Global warming might even...  NaN   \n",
       "9  Add...\\nA bunch of government scientists lande...  NaN   \n",
       "\n",
       "                    id lang  \\\n",
       "0  1067247943491702784   en   \n",
       "1  1067247939439943680   en   \n",
       "2  1067247941960626176   en   \n",
       "3  1067247940094222342   en   \n",
       "4  1067247957508911105   en   \n",
       "5  1067247961434861568   en   \n",
       "6  1067247967361556480   en   \n",
       "7  1067247966363238400   en   \n",
       "8  1067247979118120960   en   \n",
       "9  1067248002178404353   en   \n",
       "\n",
       "                                               place  ...  User_Screen_Name  \\\n",
       "0                                                NaN  ...        All4Feedom   \n",
       "1                                                NaN  ...    Zwickyhumason1   \n",
       "2                                                NaN  ...          rbmumsie   \n",
       "3                                                NaN  ...     booksanescape   \n",
       "4  {'full_name': 'Iloilo City, Western Visayas', ...  ...         icleiseas   \n",
       "5                                                NaN  ...          i_sharyn   \n",
       "6                                                NaN  ...    RobertLongView   \n",
       "7                                                NaN  ...     thinkprogress   \n",
       "8                                                NaN  ...    PaulusMcNaulus   \n",
       "9                                                NaN  ...    AlamoOnTheRise   \n",
       "\n",
       "  User_Status_Count User_Followers_Count User_Friends_Count  \\\n",
       "0              1176                   51                 33   \n",
       "1               577                   11                 48   \n",
       "2            118235                  952                609   \n",
       "3             83238                12482              13600   \n",
       "4              2718                  996                386   \n",
       "5              8062                   27                194   \n",
       "6              4464                   27                108   \n",
       "7            152355               826870                892   \n",
       "8              5059                    6                 53   \n",
       "9            132668                26195              26169   \n",
       "\n",
       "  User_Verified_Status         User_Account_Start_Date  \\\n",
       "0                False  Thu May 24 05:06:44 +0000 2018   \n",
       "1                False  Fri Oct 14 19:01:14 +0000 2016   \n",
       "2                False  Sun Apr 21 23:44:26 +0000 2013   \n",
       "3                False  Thu Jun 13 03:15:34 +0000 2013   \n",
       "4                False  Fri Dec 13 09:50:27 +0000 2013   \n",
       "5                False  Tue Jul 03 00:55:41 +0000 2018   \n",
       "6                False  Thu Sep 06 02:27:46 +0000 2012   \n",
       "7                 True  Thu Jul 09 20:42:08 +0000 2009   \n",
       "8                False  Sun Apr 24 15:20:14 +0000 2016   \n",
       "9                False  Thu Apr 01 02:56:57 +0000 2010   \n",
       "\n",
       "                   User_Location                Tweet_Location  \\\n",
       "0                                                          NaN   \n",
       "1  Zwettl-Lower Austria, Austria                           NaN   \n",
       "2                Colorado,  USA                            NaN   \n",
       "3                 Cali Girl, USA                           NaN   \n",
       "4            Manila, Philippines  Iloilo City, Western Visayas   \n",
       "5                                                          NaN   \n",
       "6                                                          NaN   \n",
       "7               Washington, D.C.                           NaN   \n",
       "8                                                          NaN   \n",
       "9             San Antonio, Texas                           NaN   \n",
       "\n",
       "        Tweet_Location_Country Tweet_Location_Country_Code  \n",
       "0                          NaN                         NaN  \n",
       "1                          NaN                         NaN  \n",
       "2                          NaN                         NaN  \n",
       "3                          NaN                         NaN  \n",
       "4  Republic of the Philippines                          PH  \n",
       "5                          NaN                         NaN  \n",
       "6                          NaN                         NaN  \n",
       "7                          NaN                         NaN  \n",
       "8                          NaN                         NaN  \n",
       "9                          NaN                         NaN  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Redundant/Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete'key_0' column since it is simply a duplicate of the index.\n",
    "\n",
    "del tweets_full_df['key_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify all tweets are in english.  This column can be dropped\n",
    "# as well, which is shown in the next cell.\n",
    "\n",
    "tweets_full_df['lang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'entities', 'user', and 'place' columns can be deleted since all\n",
    "# the desired info has been extracted from them. The id columns\n",
    "# will be deleted as well.\n",
    "\n",
    "tweets_full_df = tweets_full_df.drop(['_id', 'entities', 'id', 'user', 'lang', 'place'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                  966055\n",
       "United States                      69830\n",
       "Washington, DC                     40745\n",
       "London                             36788\n",
       "New York, NY                       35972\n",
       "Australia                          33460\n",
       "Globally l Planet Earth            32499\n",
       "London, England                    32051\n",
       "Canada                             30939\n",
       "USA                                29918\n",
       "Finland                            28460\n",
       "Global                             26576\n",
       "California, USA                    24574\n",
       "Globally l Online l Earth          23026\n",
       "Online l Globally l Earth          22793\n",
       "United Kingdom                     20690\n",
       "Los Angeles, CA                    19736\n",
       "Earth                              18482\n",
       "UK                                 18032\n",
       "Sydney, New South Wales            16679\n",
       "New York, USA                      15279\n",
       "Florida, USA                       15199\n",
       "Worldwide                          15086\n",
       "Toronto, Ontario                   14467\n",
       "Boston, MA                         12782\n",
       "Chicago, IL                        12128\n",
       "Seattle, WA                        11608\n",
       "New York City                      11257\n",
       "Planet Earth                       11204\n",
       "England, United Kingdom            11006\n",
       "                                   ...  \n",
       "Ballymena/East Strand, P'rush          1\n",
       "6/14/18                                1\n",
       "weversekanda                           1\n",
       "Wider Caribbean region                 1\n",
       "Silent Hill North Stake                1\n",
       "Cascadian Bioregion                    1\n",
       "ART ⬇️⬇️⬇️                             1\n",
       "The Bay ☹️����                         1\n",
       "Prishtinë Kosovë                       1\n",
       "Chimbote-Perú                          1\n",
       "Ashley's world                         1\n",
       "Country roads                          1\n",
       "micay's parabatai                      1\n",
       "penarth                                1\n",
       "Onemana, Thames-Coromandel             1\n",
       "Northwest Illinois                     1\n",
       "he/him • cr: six of crows              1\n",
       "From Málaga, Spain                     1\n",
       "DUUUVAL                                1\n",
       "Not on this earth                      1\n",
       "Everywhere you're not!                 1\n",
       "Occupied Mvskoke Territory             1\n",
       "Sorrento Victoria Australia            1\n",
       "The World of Truth                     1\n",
       "Scotland, it will be free              1\n",
       "Planet krypto                          1\n",
       "In My Imagination                      1\n",
       "Dwelling in Tla'amin Territory         1\n",
       "Gladmar Saskatchewan                   1\n",
       "Malda, West Bengal, India              1\n",
       "Name: User_Location, Length: 259096, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_full_df['User_Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace blank 'User_Location' values with NaN's\n",
    "\n",
    "tweets_full_df.User_Location = tweets_full_df.User_Location.replace({\"\": np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4225416 entries, 0 to 4225415\n",
      "Data columns (total 17 columns):\n",
      "created_at                     object\n",
      "favorite_count                 int64\n",
      "full_text                      object\n",
      "geo                            object\n",
      "retweet_count                  int64\n",
      "Hashtags_List                  object\n",
      "User_Name                      object\n",
      "User_Screen_Name               object\n",
      "User_Status_Count              int64\n",
      "User_Followers_Count           int64\n",
      "User_Friends_Count             int64\n",
      "User_Verified_Status           bool\n",
      "User_Account_Start_Date        object\n",
      "User_Location                  object\n",
      "Tweet_Location                 object\n",
      "Tweet_Location_Country         object\n",
      "Tweet_Location_Country_Code    object\n",
      "dtypes: bool(1), int64(5), object(11)\n",
      "memory usage: 552.1+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_full_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change dates to datetime, insert User_Years_Active column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'created_at' column to datetime\n",
    "\n",
    "new_time_string = []\n",
    "new_time_dt = []\n",
    "\n",
    "for index, rows in tweets_full_df['created_at'].iteritems():\n",
    "    new_time_string.append(rows.replace('+0000 ', ''))\n",
    "\n",
    "for i in new_time_string:\n",
    "    i_time = datetime.datetime.strptime(i, '%a %b %d %H:%M:%S %Y')\n",
    "    i_time_str = datetime.datetime.strftime(i_time, '%m/%d/%Y')\n",
    "    new_time_dt.append(datetime.datetime.strptime(i_time_str, '%m/%d/%Y'))   \n",
    "\n",
    "tweets_full_df['created_at'] = pd.Series(new_time_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'User_Account_Start_Date' column to datetime\n",
    "\n",
    "new_time_string2 = []\n",
    "new_time_dt2 = []\n",
    "\n",
    "for index, rows in tweets_full_df['User_Account_Start_Date'].iteritems():\n",
    "    new_time_string2.append(rows.replace('+0000 ', ''))\n",
    "\n",
    "for i in new_time_string2:\n",
    "    i_time2 = datetime.datetime.strptime(i, '%a %b %d %H:%M:%S %Y')\n",
    "    i_time_str2 = datetime.datetime.strftime(i_time2, '%m/%d/%Y')\n",
    "    new_time_dt2.append(datetime.datetime.strptime(i_time_str2, '%m/%d/%Y'))   \n",
    "\n",
    "tweets_full_df['User_Account_Start_Date'] = pd.Series(new_time_dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create years_active list\n",
    "\n",
    "days_active = tweets_full_df['created_at'] - tweets_full_df['User_Account_Start_Date']\n",
    "\n",
    "years_active = []\n",
    "\n",
    "for index, rows in days_active.iteritems():\n",
    "    years_active.append(round(rows.days/365.25, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_full_df.insert(13, column = 'User_Years_Active', value = pd.Series(years_active))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Emojis from Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove emojis\n",
    "\n",
    "import emoji\n",
    "import string\n",
    "\n",
    "def give_emoji_free_text(text):\n",
    "    \n",
    "    '''\n",
    "    Takes in tweet series, removes all emojis, and returns cleaned tweet series.\n",
    "    '''\n",
    "    \n",
    "    allchars = [str for str in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text_list = []\n",
    "\n",
    "for index, rows in tweets_full_df['full_text'].iteritems():\n",
    "    rows = give_emoji_free_text(rows) # remove emojis\n",
    "    full_text_list.append(rows)\n",
    "    \n",
    "tweets_full_df['full_text'] = full_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>geo</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>Hashtags_List</th>\n",
       "      <th>User_Name</th>\n",
       "      <th>User_Screen_Name</th>\n",
       "      <th>User_Status_Count</th>\n",
       "      <th>User_Followers_Count</th>\n",
       "      <th>User_Friends_Count</th>\n",
       "      <th>User_Verified_Status</th>\n",
       "      <th>User_Account_Start_Date</th>\n",
       "      <th>User_Years_Active</th>\n",
       "      <th>User_Location</th>\n",
       "      <th>Tweet_Location</th>\n",
       "      <th>Tweet_Location_Country</th>\n",
       "      <th>Tweet_Location_Country_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4225406</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>4</td>\n",
       "      <td>\"We are in the unsustainable future.\" #climate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>[climatechange, santarosafire, climaterecovery...</td>\n",
       "      <td>Our Children's Trust</td>\n",
       "      <td>youthvgov</td>\n",
       "      <td>9388</td>\n",
       "      <td>12076</td>\n",
       "      <td>623</td>\n",
       "      <td>False</td>\n",
       "      <td>2011-03-18</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Eugene, OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225407</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>1</td>\n",
       "      <td>After #TyphoonLan passed through Tokyo: Dry st...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[TyphoonLan, ClimateChange, ClimateFinance]</td>\n",
       "      <td>RRC.AP</td>\n",
       "      <td>RRCAP_AIT</td>\n",
       "      <td>310</td>\n",
       "      <td>124</td>\n",
       "      <td>175</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Pathum Thani, Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225408</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>The EPA has canceled speaking appearances of t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Jake Cornwall</td>\n",
       "      <td>JakeM_1998</td>\n",
       "      <td>512647</td>\n",
       "      <td>1222</td>\n",
       "      <td>1794</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>2.7</td>\n",
       "      <td>United Kingdom, London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225409</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>2</td>\n",
       "      <td>Check out @levinsources minerals behind #Green...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[GreenEconomy, climatechange]</td>\n",
       "      <td>Canadian Intl Resources &amp; Development Institute</td>\n",
       "      <td>CIRDI_ICIRD</td>\n",
       "      <td>2237</td>\n",
       "      <td>1274</td>\n",
       "      <td>929</td>\n",
       "      <td>False</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Vancouver, British Columbia, Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225410</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>The EPA has canceled speaking appearances of t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electro Edward!</td>\n",
       "      <td>electro_edward</td>\n",
       "      <td>109329</td>\n",
       "      <td>44</td>\n",
       "      <td>210</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-03-04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Oklahoma, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225411</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>5</td>\n",
       "      <td>Working with satellite data, scientists detect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ian James</td>\n",
       "      <td>ByIanJames</td>\n",
       "      <td>19192</td>\n",
       "      <td>7423</td>\n",
       "      <td>1364</td>\n",
       "      <td>True</td>\n",
       "      <td>2009-04-03</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Phoenix, Arizona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225412</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>EPA pulls scientists out of climate change con...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Mohammad Keshtkar</td>\n",
       "      <td>k3shtk4r</td>\n",
       "      <td>944229</td>\n",
       "      <td>346</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>2010-09-24</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225413</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>Even the earth has rights in #Islam , so treat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[Islam, Mercy]</td>\n",
       "      <td>This Is Islam</td>\n",
       "      <td>TII99</td>\n",
       "      <td>161597</td>\n",
       "      <td>1653</td>\n",
       "      <td>1580</td>\n",
       "      <td>False</td>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>حساب للدعوة باللغة الانجليزية</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225414</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>Remember My Lai Massacre！ #ClimateChange #Anon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[ClimateChange, Anonymous, WikiLeaks]</td>\n",
       "      <td>サイダーラジオは今日も言いたい放題</td>\n",
       "      <td>applecider52</td>\n",
       "      <td>128019</td>\n",
       "      <td>4914</td>\n",
       "      <td>3163</td>\n",
       "      <td>False</td>\n",
       "      <td>2009-05-12</td>\n",
       "      <td>8.4</td>\n",
       "      <td>kyoto-Shiga</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225415</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>9</td>\n",
       "      <td>Once spoke to a woman you said she's hoping th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>Nita Cosby</td>\n",
       "      <td>5_2blue</td>\n",
       "      <td>93344</td>\n",
       "      <td>26070</td>\n",
       "      <td>22632</td>\n",
       "      <td>False</td>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        created_at  favorite_count  \\\n",
       "4225406 2017-10-23               4   \n",
       "4225407 2017-10-23               1   \n",
       "4225408 2017-10-23               0   \n",
       "4225409 2017-10-23               2   \n",
       "4225410 2017-10-23               0   \n",
       "4225411 2017-10-23               5   \n",
       "4225412 2017-10-23               0   \n",
       "4225413 2017-10-23               0   \n",
       "4225414 2017-10-23               0   \n",
       "4225415 2017-10-23               9   \n",
       "\n",
       "                                                 full_text  geo  \\\n",
       "4225406  \"We are in the unsustainable future.\" #climate...  NaN   \n",
       "4225407  After #TyphoonLan passed through Tokyo: Dry st...  NaN   \n",
       "4225408  The EPA has canceled speaking appearances of t...  NaN   \n",
       "4225409  Check out @levinsources minerals behind #Green...  NaN   \n",
       "4225410  The EPA has canceled speaking appearances of t...  NaN   \n",
       "4225411  Working with satellite data, scientists detect...  NaN   \n",
       "4225412  EPA pulls scientists out of climate change con...  NaN   \n",
       "4225413  Even the earth has rights in #Islam , so treat...  NaN   \n",
       "4225414  Remember My Lai Massacre！ #ClimateChange #Anon...  NaN   \n",
       "4225415  Once spoke to a woman you said she's hoping th...  NaN   \n",
       "\n",
       "         retweet_count                                      Hashtags_List  \\\n",
       "4225406              5  [climatechange, santarosafire, climaterecovery...   \n",
       "4225407              0        [TyphoonLan, ClimateChange, ClimateFinance]   \n",
       "4225408              0                                                 []   \n",
       "4225409              1                      [GreenEconomy, climatechange]   \n",
       "4225410              0                                                 []   \n",
       "4225411              5                                                 []   \n",
       "4225412              0                                                 []   \n",
       "4225413              0                                     [Islam, Mercy]   \n",
       "4225414              1              [ClimateChange, Anonymous, WikiLeaks]   \n",
       "4225415             10                                                 []   \n",
       "\n",
       "                                               User_Name User_Screen_Name  \\\n",
       "4225406                             Our Children's Trust        youthvgov   \n",
       "4225407                                           RRC.AP        RRCAP_AIT   \n",
       "4225408                                    Jake Cornwall       JakeM_1998   \n",
       "4225409  Canadian Intl Resources & Development Institute      CIRDI_ICIRD   \n",
       "4225410                                  Electro Edward!   electro_edward   \n",
       "4225411                                        Ian James       ByIanJames   \n",
       "4225412                                Mohammad Keshtkar         k3shtk4r   \n",
       "4225413                                    This Is Islam            TII99   \n",
       "4225414                                サイダーラジオは今日も言いたい放題     applecider52   \n",
       "4225415                                       Nita Cosby          5_2blue   \n",
       "\n",
       "         User_Status_Count  User_Followers_Count  User_Friends_Count  \\\n",
       "4225406               9388                 12076                 623   \n",
       "4225407                310                   124                 175   \n",
       "4225408             512647                  1222                1794   \n",
       "4225409               2237                  1274                 929   \n",
       "4225410             109329                    44                 210   \n",
       "4225411              19192                  7423                1364   \n",
       "4225412             944229                   346                  86   \n",
       "4225413             161597                  1653                1580   \n",
       "4225414             128019                  4914                3163   \n",
       "4225415              93344                 26070               22632   \n",
       "\n",
       "         User_Verified_Status User_Account_Start_Date  User_Years_Active  \\\n",
       "4225406                 False              2011-03-18                6.6   \n",
       "4225407                 False              2017-08-02                0.2   \n",
       "4225408                 False              2015-02-11                2.7   \n",
       "4225409                 False              2014-01-27                3.7   \n",
       "4225410                 False              2017-03-04                0.6   \n",
       "4225411                  True              2009-04-03                8.6   \n",
       "4225412                 False              2010-09-24                7.1   \n",
       "4225413                 False              2014-04-01                3.6   \n",
       "4225414                 False              2009-05-12                8.4   \n",
       "4225415                 False              2010-02-02                7.7   \n",
       "\n",
       "                               User_Location Tweet_Location  \\\n",
       "4225406                           Eugene, OR            NaN   \n",
       "4225407               Pathum Thani, Thailand            NaN   \n",
       "4225408               United Kingdom, London            NaN   \n",
       "4225409  Vancouver, British Columbia, Canada            NaN   \n",
       "4225410                        Oklahoma, USA            NaN   \n",
       "4225411                     Phoenix, Arizona            NaN   \n",
       "4225412                                  NaN            NaN   \n",
       "4225413        حساب للدعوة باللغة الانجليزية            NaN   \n",
       "4225414                          kyoto-Shiga            NaN   \n",
       "4225415                          Houston, TX            NaN   \n",
       "\n",
       "        Tweet_Location_Country Tweet_Location_Country_Code  \n",
       "4225406                    NaN                         NaN  \n",
       "4225407                    NaN                         NaN  \n",
       "4225408                    NaN                         NaN  \n",
       "4225409                    NaN                         NaN  \n",
       "4225410                    NaN                         NaN  \n",
       "4225411                    NaN                         NaN  \n",
       "4225412                    NaN                         NaN  \n",
       "4225413                    NaN                         NaN  \n",
       "4225414                    NaN                         NaN  \n",
       "4225415                    NaN                         NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_full_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataframe as pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets_full2_df.pkl', 'wb') as to_write:\n",
    "    pickle.dump(tweets_full_df, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Notebook: \"Project_04_Classifier_R1\"\n",
    "- In this notebook, the tweets in `tweets_full_df` will be analyzed and classified as either \"believer\" or \"denier\" tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Tweet Cleanup (NOT USED)**\n",
    "- *integrated into CountVectorizer in next notebook*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Remove the following characteristics from the tweets using custom function `tweet_cleanup`:*\n",
    "    - *line breaks*\n",
    "    - *URL's*\n",
    "    - *emojis*\n",
    "    - *numbers*\n",
    "    - *capital letters*\n",
    "    - *punctuation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tweet_cleanup(tweet_dataframe):\n",
    "\n",
    "#     '''\n",
    "#     Takes in tweet dataframe and cleans up the tweet column by removing line breaks,\n",
    "#     URL's, emojis, numbers, capital letters, and punctuation. Returns complete dataframe\n",
    "#     with cleaned tweet column.\n",
    "#     '''\n",
    "\n",
    "#     full_text_list = []\n",
    "\n",
    "#     for index, rows in tweet_dataframe['full_text'].iteritems():\n",
    "#         rows = rows.replace('\\n', ' ') # remove line breaks\n",
    "#         rows = re.sub(r\"\\bhttps://t.co/\\w+\", '', rows) # remove URL's\n",
    "#         rows = give_emoji_free_text(rows) # remove emojis\n",
    "#         full_text_list.append(rows)\n",
    "    \n",
    "#     tweet_dataframe['full_text'] = full_text_list\n",
    "\n",
    "#     # Remove, numbers, capital letters, and punctuation\n",
    "#     alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ',x)\n",
    "#     punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "#     tweet_dataframe['full_text'] = tweet_dataframe.full_text.map(alphanumeric).map(punc_lower)\n",
    "    \n",
    "#     return tweet_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_clean_df = tweet_cleanup(tweets_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tweets_subset2.pkl','rb') as read_file:\n",
    "#     tweets_subset2_df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us_abbrevs = ['US', 'USA', 'United States',\n",
    "# 'Alabama',\n",
    "# 'AL',\n",
    "# 'Alaska',\n",
    "# 'AK',\n",
    "# 'Arizona',\n",
    "# 'AZ',\n",
    "# 'Arkansas',\n",
    "# 'AR',\n",
    "# 'California',\n",
    "# 'CA',\n",
    "# 'Colorado',\n",
    "# 'CO',\n",
    "# 'Connecticut',\n",
    "# 'CT',\n",
    "# 'Delaware',\n",
    "# 'DE',\n",
    "# 'Florida',\n",
    "# 'FL',\n",
    "# 'Georgia',\n",
    "# 'GA',\n",
    "# 'Hawaii',\n",
    "# 'HI',\n",
    "# 'Idaho',\n",
    "# 'ID',\n",
    "# 'Illinois',\n",
    "# 'IL',\n",
    "# 'Indiana',\n",
    "# 'IN',\n",
    "# 'Iowa',\n",
    "# 'IA',\n",
    "# 'Kansas',\n",
    "# 'KS',\n",
    "# 'Kentucky',\n",
    "# 'KY',\n",
    "# 'Louisiana',\n",
    "# 'LA',\n",
    "# 'Maine',\n",
    "# 'ME',\n",
    "# 'Maryland',\n",
    "# 'MD',\n",
    "# 'Massachusetts',\n",
    "# 'MA',\n",
    "# 'Michigan',\n",
    "# 'MI',\n",
    "# 'Minnesota',\n",
    "# 'MN',\n",
    "# 'Mississippi',\n",
    "# 'MS',\n",
    "# 'Missouri',\n",
    "# 'MO',\n",
    "# 'Montana',\n",
    "# 'MT',\n",
    "# 'Nebraska',\n",
    "# 'NE',\n",
    "# 'Nevada',\n",
    "# 'NV',\n",
    "# 'New Hampshire',\n",
    "# 'NH',\n",
    "# 'New Jersey',\n",
    "# 'NJ',\n",
    "# 'New Mexico',\n",
    "# 'NM',\n",
    "# 'New York',\n",
    "# 'NY',\n",
    "# 'North Carolina',\n",
    "# 'NC',\n",
    "# 'North Dakota',\n",
    "# 'ND',\n",
    "# 'Ohio',\n",
    "# 'OH',\n",
    "# 'Oklahoma',\n",
    "# 'OK',\n",
    "# 'Oregon',\n",
    "# 'OR',\n",
    "# 'Pennsylvania',\n",
    "# 'PA',\n",
    "# 'Rhode Island',\n",
    "# 'RI',\n",
    "# 'South Carolina',\n",
    "# 'SC',\n",
    "# 'South Dakota',\n",
    "# 'SD',\n",
    "# 'Tennessee',\n",
    "# 'TN',\n",
    "# 'Texas',\n",
    "# 'TX',\n",
    "# 'Utah',\n",
    "# 'UT',\n",
    "# 'Vermont',\n",
    "# 'VT',\n",
    "# 'Virginia',\n",
    "# 'VA',\n",
    "# 'Washington',\n",
    "# 'WA',\n",
    "# 'West Virginia',\n",
    "# 'WV',\n",
    "# 'Wisconsin',\n",
    "# 'WI',\n",
    "# 'Wyoming',\n",
    "# 'WY',\n",
    "# 'District of Columbia',\n",
    "# 'DC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90                     Boulder, CO\n",
       "91                        New York\n",
       "92                       Worldwide\n",
       "93                            here\n",
       "94          Montréal Québec Canada\n",
       "95             Berlin, Deutschland\n",
       "96                           World\n",
       "97                        Canberra\n",
       "98                 London, England\n",
       "99                Rome, Italy (EU)\n",
       "100               Iqaluit, Nunavut\n",
       "101                        Finland\n",
       "102            Canterbury, England\n",
       "103                      Hong Kong\n",
       "104                       Canberra\n",
       "105            HamOnt via Brampton\n",
       "106    Melbourne, Vic. Bowen, Q'ld\n",
       "107                  Cambridge, MA\n",
       "Name: User_Location, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweets_subset2_df['User_Location'][90:108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_dict = {}\n",
    "\n",
    "# for index, rows in tweets_subset2_df['User_Location'].iteritems():\n",
    "#     for loc in us_abbrevs:\n",
    "#         if str(loc) in str(rows):\n",
    "#             location_dict[index] = rows\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtag_collapse = []\n",
    "\n",
    "# for index, rows in tweets_subset2_df['Hashtags_List'].iteritems():\n",
    "#     for i in rows:\n",
    "#         hashtag_collapse.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LNP               184\n",
       "environmental     182\n",
       "UN                182\n",
       "innovation        181\n",
       "KAG               179\n",
       "oceans            178\n",
       "Resist            178\n",
       "abpoli            177\n",
       "GOP               176\n",
       "Energy            176\n",
       "Weather           175\n",
       "floods            175\n",
       "VoteThemOut       174\n",
       "Green             173\n",
       "Democracy         173\n",
       "leadership        172\n",
       "ocean             172\n",
       "WaterIsLife       171\n",
       "CCOT              170\n",
       "technology        169\n",
       "ableg             168\n",
       "Ontario           166\n",
       "MAGA2018          166\n",
       "WakeUpAmerica     166\n",
       "VoteDemocrat      166\n",
       "wildlife          166\n",
       "conservation      163\n",
       "KAG2020           163\n",
       "MAGA2020          163\n",
       "RenewablesNow     163\n",
       "trump             163\n",
       "activism          162\n",
       "SmartNews         162\n",
       "Florida           162\n",
       "KAG2018           161\n",
       "feedly            161\n",
       "change            160\n",
       "Christian         160\n",
       "flooding          159\n",
       "deforestation     159\n",
       "Armageddon        158\n",
       "vegan             157\n",
       "Solar             156\n",
       "renewable         155\n",
       "Geoengineering    153\n",
       "Africa            153\n",
       "USA               152\n",
       "AirPollution      151\n",
       "COP24             151\n",
       "globalcitizen     151\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.Series(hashtag_collapse).value_counts()[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
